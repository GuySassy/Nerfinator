{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-21T12:01:02.734581300Z",
     "start_time": "2024-02-21T12:00:55.352964800Z"
    }
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import numpy as np\n",
    "model = YOLO(\"yolov8n.pt\") "
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found https://ultralytics.com/images/bus.jpg locally at bus.jpg\n",
      "image 1/1 E:\\PycharmProjects\\Nerfinator\\object detection\\bus.jpg: 640x480 4 persons, 1 bus, 1 stop sign, 70.2ms\n",
      "Speed: 2.6ms preprocess, 70.2ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Results saved to \u001B[1mE:\\PycharmProjects\\Nerfinator\\runs\\detect\\predict6\u001B[0m\n",
      "1 label saved to E:\\PycharmProjects\\Nerfinator\\runs\\detect\\predict6\\labels\n"
     ]
    }
   ],
   "source": [
    "results = model.predict(source=\"https://ultralytics.com/images/bus.jpg\", save = True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T16:41:33.820007300Z",
     "start_time": "2024-02-20T16:41:33.185827200Z"
    }
   },
   "id": "e68f64ad3b2636ab",
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image 1/1 E:\\PycharmProjects\\Nerfinator\\object detection\\DSCF0199.JPG: 480x640 1 person, 1 pizza, 1 refrigerator, 76.9ms\n",
      "Speed: 2.6ms preprocess, 76.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001B[1mE:\\PycharmProjects\\Nerfinator\\runs\\detect\\predict6\u001B[0m\n",
      "2 labels saved to E:\\PycharmProjects\\Nerfinator\\runs\\detect\\predict6\\labels\n"
     ]
    }
   ],
   "source": [
    "results = model.predict(source=\"DSCF0199.JPG\", save = True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T16:42:39.831957300Z",
     "start_time": "2024-02-20T16:42:38.968801100Z"
    }
   },
   "id": "d49955255d6f89b8",
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image 1/1 E:\\PycharmProjects\\Nerfinator\\object detection\\DSCF0228.JPG: 480x640 11 persons, 3 cars, 1 chair, 67.7ms\n",
      "Speed: 3.1ms preprocess, 67.7ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001B[1mE:\\PycharmProjects\\Nerfinator\\runs\\detect\\predict6\u001B[0m\n",
      "3 labels saved to E:\\PycharmProjects\\Nerfinator\\runs\\detect\\predict6\\labels\n"
     ]
    }
   ],
   "source": [
    "results = model.predict(source=\"DSCF0228.JPG\", save = True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T16:42:50.637381200Z",
     "start_time": "2024-02-20T16:42:49.786638300Z"
    }
   },
   "id": "3dd7e121ec01ccae",
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image 1/1 E:\\PycharmProjects\\Nerfinator\\object detection\\20240220_182408.jpg: 480x640 2 persons, 3 couchs, 1 remote, 1 book, 70.9ms\n",
      "Speed: 3.1ms preprocess, 70.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Results saved to \u001B[1mE:\\PycharmProjects\\Nerfinator\\runs\\detect\\predict6\u001B[0m\n",
      "4 labels saved to E:\\PycharmProjects\\Nerfinator\\runs\\detect\\predict6\\labels\n"
     ]
    }
   ],
   "source": [
    "results = model.predict(source=\"20240220_182408.jpg\", save = True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T16:47:25.206123800Z",
     "start_time": "2024-02-20T16:47:24.098429Z"
    }
   },
   "id": "8f2ac1702a9534a7",
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([65., 57., 73., 57., 57.,  0.,  0.])\n",
      "conf: tensor([0.7555, 0.7101, 0.6928, 0.4861, 0.3968, 0.3813, 0.2508])\n",
      "data: tensor([[1.7920e+03, 1.8068e+03, 2.0233e+03, 2.0476e+03, 7.5550e-01, 6.5000e+01],\n",
      "        [1.0127e+03, 3.7678e+02, 4.5796e+03, 2.8214e+03, 7.1006e-01, 5.7000e+01],\n",
      "        [2.5708e+03, 1.6682e+03, 3.0645e+03, 1.9889e+03, 6.9282e-01, 7.3000e+01],\n",
      "        [1.0278e+03, 3.8229e+02, 4.5925e+03, 1.8315e+03, 4.8613e-01, 5.7000e+01],\n",
      "        [2.5488e+03, 5.2011e+02, 4.6210e+03, 3.1710e+03, 3.9681e-01, 5.7000e+01],\n",
      "        [3.2219e+03, 4.8497e+02, 4.0148e+03, 1.2504e+03, 3.8130e-01, 0.0000e+00],\n",
      "        [2.4025e+03, 4.8436e+02, 3.8769e+03, 1.6660e+03, 2.5075e-01, 0.0000e+00]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (3468, 4624)\n",
      "shape: torch.Size([7, 6])\n",
      "xywh: tensor([[1907.6567, 1927.2207,  231.2362,  240.8186],\n",
      "        [2796.1514, 1599.1072, 3566.8577, 2444.6636],\n",
      "        [2817.6323, 1828.5566,  493.7483,  320.7660],\n",
      "        [2810.1523, 1106.9105, 3564.6113, 1449.2343],\n",
      "        [3584.8960, 1845.5648, 2072.2273, 2650.9026],\n",
      "        [3618.3428,  867.7019,  792.9556,  765.4622],\n",
      "        [3139.6909, 1075.1628, 1474.4631, 1181.6105]])\n",
      "xywhn: tensor([[0.4126, 0.5557, 0.0500, 0.0694],\n",
      "        [0.6047, 0.4611, 0.7714, 0.7049],\n",
      "        [0.6093, 0.5273, 0.1068, 0.0925],\n",
      "        [0.6077, 0.3192, 0.7709, 0.4179],\n",
      "        [0.7753, 0.5322, 0.4481, 0.7644],\n",
      "        [0.7825, 0.2502, 0.1715, 0.2207],\n",
      "        [0.6790, 0.3100, 0.3189, 0.3407]])\n",
      "xyxy: tensor([[1792.0386, 1806.8114, 2023.2748, 2047.6300],\n",
      "        [1012.7224,  376.7753, 4579.5801, 2821.4390],\n",
      "        [2570.7581, 1668.1737, 3064.5063, 1988.9397],\n",
      "        [1027.8467,  382.2934, 4592.4580, 1831.5276],\n",
      "        [2548.7825,  520.1136, 4621.0098, 3171.0161],\n",
      "        [3221.8650,  484.9709, 4014.8206, 1250.4330],\n",
      "        [2402.4595,  484.3577, 3876.9226, 1665.9681]])\n",
      "xyxyn: tensor([[0.3876, 0.5210, 0.4376, 0.5904],\n",
      "        [0.2190, 0.1086, 0.9904, 0.8136],\n",
      "        [0.5560, 0.4810, 0.6627, 0.5735],\n",
      "        [0.2223, 0.1102, 0.9932, 0.5281],\n",
      "        [0.5512, 0.1500, 0.9994, 0.9144],\n",
      "        [0.6968, 0.1398, 0.8683, 0.3606],\n",
      "        [0.5196, 0.1397, 0.8384, 0.4804]])\n"
     ]
    }
   ],
   "source": [
    "for result in results:\n",
    "    print(result.boxes)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-20T17:02:51.909809300Z",
     "start_time": "2024-02-20T17:02:51.885736600Z"
    }
   },
   "id": "e53ab80fcc32495b",
   "execution_count": 51
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m results \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241m.\u001B[39mdetect(source\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m20240220_182408.jpg\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "results = model.detect(source=\"20240220_182408.jpg\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-21T11:58:38.310473900Z",
     "start_time": "2024-02-21T11:58:38.014613100Z"
    }
   },
   "id": "5676aee4ca38998",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 480x640 2 persons, 3 couchs, 1 remote, 1 book, 151.1ms\n",
      "Speed: 7.7ms preprocess, 151.1ms inference, 14.9ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(\"20240220_182408.jpg\")\n",
    "results = model(img)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-21T12:01:38.210970300Z",
     "start_time": "2024-02-21T12:01:36.162441600Z"
    }
   },
   "id": "bd84bbe91f546785",
   "execution_count": 3
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
